{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTkEewzaX6br"
   },
   "source": [
    "# Explainability for Classifiers: GradCAM, OcclusionSensitivity et al.\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mtwenzel/teaching/blob/master/01 Explainability using tf_explain.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/mtwenzel/teaching/blob/master/01 Explainability using tf_explain.ipynb\n",
    "\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>\n",
    "\n",
    "This notebook shows for MNIST and for a medical example (Parkinson SPECT classification) how different visualization methods compare.\n",
    "\n",
    "The code inherits from the 'tf_explain' original authors' example code and adapts it to the Parkinson example.\n",
    "\n",
    "Use as a basis for own experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqbmiO8j_zyq"
   },
   "source": [
    "# Preparations\n",
    "\n",
    "Install TensorFlow 2.0.0 rc0 and TFP 0.8.0 rc0 below, if not running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l07VQCX85TKF"
   },
   "outputs": [],
   "source": [
    "#@title Install TensorFlow { display-mode: \"form\" }\n",
    "TF_Installation = 'TF2 RC0 (GPU)' #@param ['TF2 Nightly (GPU)', 'TF2 RC0 (GPU)', 'TF2 Stable (GPU)', 'TF1 Nightly (GPU)', 'TF1 Stable (GPU)','System']\n",
    "# added 2.0.0-rc0\n",
    "if TF_Installation == 'TF2 Nightly (GPU)':\n",
    "  !pip install -q --upgrade tf-nightly-gpu-2.0-preview\n",
    "  print('Installation of `tf-nightly-gpu-2.0-preview` complete.')\n",
    "elif TF_Installation == 'TF2 RC0 (GPU)':\n",
    "  !pip install -q --upgrade tensorflow-gpu==2.0.0-rc0\n",
    "  print('Installation of `tensorflow-gpu==2.0.0-rc0` complete. Use with tensorflow_probability=0.8.0-rc0')\n",
    "elif TF_Installation == 'TF2 Stable (GPU)':\n",
    "  !pip install -q --upgrade tensorflow-gpu==2.0.0-alpha0\n",
    "  print('Installation of `tensorflow-gpu==2.0.0-alpha0` complete.')\n",
    "elif TF_Installation == 'TF1 Nightly (GPU)':\n",
    "  !pip install -q --upgrade tf-nightly-gpu\n",
    "  print('Installation of `tf-nightly-gpu` complete.')\n",
    "elif TF_Installation == 'TF1 Stable (GPU)':\n",
    "  !pip install -q --upgrade tensorflow-gpu\n",
    "  print('Installation of `tensorflow-gpu` complete.')\n",
    "elif TF_Installation == 'System':\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError('Selection Error: Please select a valid '\n",
    "                   'installation option.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAKm6re56Sim"
   },
   "outputs": [],
   "source": [
    "#@title Install tensorflow_probability { display-mode: \"form\" }\n",
    "TFP_Installation = \"0.8.0-rc0\" #@param [\"0.8.0-rc0\", \"Nightly\", \"Stable\", \"System\"]\n",
    "\n",
    "if TFP_Installation == \"Nightly\":\n",
    "  !pip install -q tfp-nightly\n",
    "  print(\"Installation of `tfp-nightly` complete.\")\n",
    "elif TFP_Installation == \"0.8.0-rc0\":\n",
    "  !pip install -q --upgrade tensorflow-probability==0.8.0-rc0\n",
    "  print(\"Installation of `tensorflow-probability` complete.\")\n",
    "elif TFP_Installation == \"Stable\":\n",
    "  !pip install -q --upgrade tensorflow-probability\n",
    "  print(\"Installation of `tensorflow-probability` complete.\")\n",
    "elif TFP_Installation == \"System\":\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError(\"Selection Error: Please select a valid \"\n",
    "                   \"installation option.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "YE4E0TjDy22W"
   },
   "outputs": [],
   "source": [
    "#@title Check GPU availability and TF version. Activate TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "print(tf.__version__ )# Has to be 2.0 for this notebook to work...\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "-4zKLYqTzFFd"
   },
   "outputs": [],
   "source": [
    "#@title Install required python packages and utility packages.\n",
    "# https://github.com/sicara/tf-explain\n",
    "try:\n",
    "  import tf_explain as tfx\n",
    "except:\n",
    "  !pip install tf_explain\n",
    "  import tf_explain as tfx\n",
    "\n",
    "# https://github.com/CyberZHG/keras-radam\n",
    "try:\n",
    "  from keras_radam.training import RAdamOptimizer # for TF\n",
    "except:\n",
    "  !pip install keras-rectified-adam\n",
    "  from keras_radam.training import RAdamOptimizer\n",
    "    \n",
    "from urllib.request import urlopen\n",
    "try:\n",
    "  import utilities\n",
    "except:\n",
    "  url = 'https://github.com/mtwenzel/utilities/raw/master/utilities.py'\n",
    "  resp = urlopen(url)\n",
    "  temp = open(\"utilities.py\", \"wb\")\n",
    "  temp.write(resp.read())\n",
    "  temp.close()\n",
    "  import utilities\n",
    "\n",
    "try:\n",
    "  import data_loaders\n",
    "except:\n",
    "  url = 'https://github.com/mtwenzel/utilities/raw/master/data_loaders.py'\n",
    "  resp = urlopen(url)\n",
    "  temp = open(\"data_loaders.py\", \"wb\")\n",
    "  temp.write(resp.read())\n",
    "  temp.close()\n",
    "  import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4m82bScJy22g"
   },
   "outputs": [],
   "source": [
    "#@title Further imports and setup {display-mode:\"form\"}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense,GlobalAveragePooling2D,concatenate,Flatten, MaxPooling2D, BatchNormalization, Dropout, SpatialDropout2D\n",
    "from tensorflow.keras.applications import InceptionV3,DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eq4GUBJiy22i"
   },
   "outputs": [],
   "source": [
    "#@title Prepare the data. {display-mode:'form'}\n",
    "TARGET_SIZE = (96,96) # Square images because of visualization library...\n",
    "paths_dict = {'train': './data/PPMI-classification/all_2d_train',\n",
    "             'val': './data/PPMI-classification/all_2d_val',\n",
    "             'test': './data/PPMI-classification/all_2d_val'}\n",
    "\n",
    "train_generator, val_generator, test_generator = data_loaders.provide_PPMI_dataset(paths_dict, target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U808MnKQAUbw"
   },
   "source": [
    "# Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9sMARety22k"
   },
   "outputs": [],
   "source": [
    "#@title Model definition\n",
    "input_image = Input(shape=TARGET_SIZE+(1,))\n",
    "\n",
    "x = BatchNormalization()(input_image)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', strides=(2,2), name='EarlyConv')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=96, kernel_size=(3,3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=96, kernel_size=(3,3), activation='relu', strides=(2,2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=96, kernel_size=(3,3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=96, kernel_size=(3,3), activation='relu', strides=(2,2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', name='LastConv')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "preds = Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model = Model(inputs=input_image,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsiM4tMMy22m"
   },
   "outputs": [],
   "source": [
    "#@title Simple model definition\n",
    "input_image = Input(shape=TARGET_SIZE+(1,))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=(7,7), activation='relu', name='EarlyConv')(input_image)\n",
    "x = Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
    "x = Conv2D(filters=64, kernel_size=(5,5), activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', name='LastConv')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "preds = Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model = Model(inputs=input_image,outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12uJJHn1y22o"
   },
   "outputs": [],
   "source": [
    "radam = RAdamOptimizer(learning_rate=1e-3)\n",
    "model.compile(optimizer=radam, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "7HPYE0wdy22r"
   },
   "outputs": [],
   "source": [
    "#@title Create the callbacks for visualization\n",
    "#@markdown To provide some illustration, several callbacks are instantiated. Not all are used below, though.\n",
    "\n",
    "#@markdown Double-click the header row to expand this cell and inspect the definitions. \n",
    "\n",
    "x_val_g = val_generator.next()\n",
    "x_val_img = np.array(x_val_g[0])\n",
    "x_val_lbl = np.array(x_val_g[1])\n",
    "val_class_zero = (np.array([\n",
    "    el for el, label in zip(x_val_img, x_val_lbl)\n",
    "    if np.all(label == np.array([1] + [0]))\n",
    "][0:9]), None)\n",
    "val_class_one = (np.array([\n",
    "    el for el, label in zip(x_val_img, x_val_lbl)\n",
    "    if np.all(label == np.array([0] + [1]))\n",
    "][0:9]), None)\n",
    "\n",
    "cam_cb_00 = tfx.callbacks.GradCAMCallback(val_class_zero, layer_name='LastConv', class_index=0)\n",
    "cam_cb_01 = tfx.callbacks.GradCAMCallback(val_class_zero, layer_name='LastConv', class_index=1)\n",
    "cam_cb_10 = tfx.callbacks.GradCAMCallback(val_class_one, layer_name='LastConv', class_index=0)\n",
    "cam_cb_11 = tfx.callbacks.GradCAMCallback(val_class_one, layer_name='LastConv', class_index=1)\n",
    "occ_cb_00 =  tfx.callbacks.OcclusionSensitivityCallback(val_class_zero,class_index=0, patch_size=8)\n",
    "occ_cb_01 =  tfx.callbacks.OcclusionSensitivityCallback(val_class_zero,class_index=1, patch_size=8)\n",
    "occ_cb_10 =  tfx.callbacks.OcclusionSensitivityCallback(val_class_one,class_index=0, patch_size=8)\n",
    "occ_cb_11 =  tfx.callbacks.OcclusionSensitivityCallback(val_class_one,class_index=1, patch_size=8)\n",
    "tf_cb = tf.keras.callbacks.TensorBoard(histogram_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj-_CxmLy22t"
   },
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs. Use the callbacks only afterwards to speed up the process.\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                              epochs=50,\n",
    "                             validation_data=val_generator,\n",
    "                             validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                             verbose=1,\n",
    "                             callbacks=[tf_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wsR2gqIy22x"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFZ2ADwly22v"
   },
   "outputs": [],
   "source": [
    "# After that, only train two epochs to generate the visualizations. This is costly!\n",
    "# Look into the embedded TensorBoard above to see results.\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                              epochs=30,\n",
    "                             validation_data=val_generator,\n",
    "                             validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                             verbose=2,\n",
    "                             callbacks=[cam_cb_00, cam_cb_01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zs9m2uLty22d"
   },
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "\n",
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cyVnjXyy22z"
   },
   "source": [
    "# Proceed to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjhE1aw-y22z"
   },
   "outputs": [],
   "source": [
    "# Define a prediction function from the model, setting the learning phase to \"learn\" to let dropout be active.\n",
    "# Caveat: Don't use with e.g. BatchNorm.\n",
    "f = K.function([model.layers[0].input, K.learning_phase()],\n",
    "               [model.layers[-1].output])\n",
    "\n",
    "# This takes some memory!\n",
    "def predict_with_uncertainty(f, x, no_classes, n_iter=20):\n",
    "    result = np.zeros((n_iter,) + (x.shape[0], no_classes) )\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result[i,:, :] = f((x, 1))[0]\n",
    "    prediction = result.mean(axis=0)\n",
    "    uncertainty = result.std(axis=0)\n",
    "    return prediction, uncertainty, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybCpHJSdy221"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "x_test = test_generator.next()\n",
    "x_test = np.array(x_test[0])\n",
    "p,u,r = predict_with_uncertainty(f,x_test[0:10],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dutz1G34y224"
   },
   "outputs": [],
   "source": [
    "plot, axs = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "sns.distplot(r[:,0,0], bins=20, ax=axs[0][0])\n",
    "sns.distplot(r[:,1,0], bins=20, ax=axs[1][0])\n",
    "sns.distplot(r[:,2,0], bins=20, ax=axs[0][1])\n",
    "sns.distplot(r[:,3,0], bins=20, ax=axs[1][1])\n",
    "sns.distplot(r[:,4,0], bins=20, ax=axs[0][2])\n",
    "sns.distplot(r[:,5,0], bins=20, ax=axs[1][2])\n",
    "sns.distplot(r[:,6,0], bins=20, ax=axs[0][3])\n",
    "sns.distplot(r[:,7,0], bins=20, ax=axs[1][3])\n",
    "sns.distplot(r[:,8,0], bins=20, ax=axs[0][4])\n",
    "sns.distplot(r[:,9,0], bins=20, ax=axs[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BDyzSeMy226"
   },
   "outputs": [],
   "source": [
    "T = 10\n",
    "Yt_hat = np.array([model.predict_generator(test_generator, steps=1) for _ in range(T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGJamlYNy227"
   },
   "outputs": [],
   "source": [
    "model_metrics = model.evaluate_generator(test_generator, steps=1)\n",
    "predictions = model.predict_generator(test_generator, steps=1)\n",
    "preds = list(zip(predictions[:,0],predictions[:,1]))\n",
    "\n",
    "print(model.metrics_names, model_metrics)\n",
    "\n",
    "result = list(zip(test_generator.filenames, preds))\n",
    "with open('results_BaselineModel2D_ppmiOnUKEall_Uncertainty', 'w') as f:\n",
    "    f.write(repr(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1gJ0GOVy229"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15B2xvXPAyCd"
   },
   "source": [
    "# A toy example from the `tf_explain` authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uUaQEVhNy22_",
    "outputId": "367bb78c-82cf-4974-e27b-237b0d1cf2b3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_explain\n",
    "\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "AVAILABLE_DATASETS = {\n",
    "    'mnist': tf.keras.datasets.mnist,\n",
    "    'fashion_mnist': tf.keras.datasets.fashion_mnist,\n",
    "}\n",
    "DATASET_NAME = 'mnist'  # Choose between \"mnist\" and \"fashion_mnist\"\n",
    "\n",
    "# Load dataset\n",
    "dataset = AVAILABLE_DATASETS[DATASET_NAME]\n",
    "(train_images, train_labels), (test_images, test_labels) = dataset.load_data()\n",
    "\n",
    "# Convert from (28, 28) images to (28, 28, 1)\n",
    "train_images = train_images[..., tf.newaxis]\n",
    "test_images = test_images[..., tf.newaxis]\n",
    "\n",
    "# One hot encore labels 0, 1, .., 9 to [0, 0, .., 1, 0, 0]\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Create model\n",
    "img_input = tf.keras.Input(INPUT_SHAPE)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(img_input)\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name='target_layer')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(img_input, x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Select a subset of the validation data to examine\n",
    "# Here, we choose 5 elements with label \"0\" == [1, 0, 0, .., 0]\n",
    "validation_class_zero = (np.array([\n",
    "    el for el, label in zip(test_images, test_labels)\n",
    "    if np.all(label == np.array([1] + [0] * 9))\n",
    "][0:5]), None)\n",
    "# Select a subset of the validation data to examine\n",
    "# Here, we choose 5 elements with label \"4\" == [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "validation_class_fours = (np.array([\n",
    "    el for el, label in zip(test_images, test_labels)\n",
    "    if np.all(label == np.array([0] * 4 + [1] + [0] * 5))\n",
    "][0:5]), None)\n",
    "\n",
    "# Instantiate callbacks\n",
    "# class_index value should match the validation_data selected above\n",
    "callbacks = [\n",
    "    tf_explain.callbacks.GradCAMCallback(validation_class_zero, 'target_layer', class_index=0),\n",
    "    tf_explain.callbacks.GradCAMCallback(validation_class_fours, 'target_layer', class_index=4),\n",
    "    tf_explain.callbacks.ActivationsVisualizationCallback(validation_class_zero, layers_name=['target_layer']),\n",
    "    tf_explain.callbacks.SmoothGradCallback(validation_class_zero, class_index=0, num_samples=15, noise=1.),\n",
    "    tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_zero, class_index=0, patch_size=4),\n",
    "]\n",
    "\n",
    "# Start training\n",
    "model.fit(train_images, train_labels, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvBwH_aHy23D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Explainability using tf_explain",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

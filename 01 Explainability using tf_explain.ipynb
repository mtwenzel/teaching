{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Explainability using tf_explain",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTkEewzaX6br"
      },
      "source": [
        "# Explainability for Classifiers: GradCAM, OcclusionSensitivity et al.\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mtwenzel/teaching/blob/master/01 Explainability using tf_explain.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/mtwenzel/teaching/blob/master/01 Explainability using tf_explain.ipynb\n",
        "\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br/><br/><br/>\n",
        "\n",
        "This notebook shows for MNIST and for a medical example (Parkinson SPECT classification) how different visualization methods compare.\n",
        "\n",
        "The code inherits from the 'tf_explain' original authors' example code and adapts it to the Parkinson example.\n",
        "\n",
        "Use as a basis for own experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqbmiO8j_zyq"
      },
      "source": [
        "# Preparations\n",
        "\n",
        "Install TensorFlow 2.0.0 rc0 and TFP 0.8.0 rc0 below, if not running locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM2budydWBdx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Remove Tensorboard logs of previous runs\n",
        "#@markdown Don't execute if you don't want to loose logs. \n",
        "%rm -rf logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l07VQCX85TKF",
        "colab": {}
      },
      "source": [
        "#@title Install TensorFlow { display-mode: \"form\" }\n",
        "TF_Installation = 'TF2 RC0 (GPU)' #@param ['TF2 Nightly (GPU)', 'TF2 RC0 (GPU)', 'TF2 Stable (GPU)', 'TF1 Nightly (GPU)', 'TF1 Stable (GPU)','System']\n",
        "# added 2.0.0-rc0\n",
        "if TF_Installation == 'TF2 Nightly (GPU)':\n",
        "  !pip install -q --upgrade tf-nightly-gpu-2.0-preview\n",
        "  print('Installation of `tf-nightly-gpu-2.0-preview` complete.')\n",
        "elif TF_Installation == 'TF2 RC0 (GPU)':\n",
        "  !pip install -q --upgrade tensorflow-gpu==2.0.0-rc0\n",
        "  print('Installation of `tensorflow-gpu==2.0.0-rc0` complete. Use with tensorflow_probability=0.8.0-rc0')\n",
        "elif TF_Installation == 'TF2 Stable (GPU)':\n",
        "  !pip install -q --upgrade tensorflow-gpu==2.0.0-alpha0\n",
        "  print('Installation of `tensorflow-gpu==2.0.0-alpha0` complete.')\n",
        "elif TF_Installation == 'TF1 Nightly (GPU)':\n",
        "  !pip install -q --upgrade tf-nightly-gpu\n",
        "  print('Installation of `tf-nightly-gpu` complete.')\n",
        "elif TF_Installation == 'TF1 Stable (GPU)':\n",
        "  !pip install -q --upgrade tensorflow-gpu\n",
        "  print('Installation of `tensorflow-gpu` complete.')\n",
        "elif TF_Installation == 'System':\n",
        "  pass\n",
        "else:\n",
        "  raise ValueError('Selection Error: Please select a valid '\n",
        "                   'installation option.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JAKm6re56Sim",
        "colab": {}
      },
      "source": [
        "#@title Install tensorflow_probability { display-mode: \"form\" }\n",
        "TFP_Installation = \"0.8.0-rc0\" #@param [\"0.8.0-rc0\", \"Nightly\", \"Stable\", \"System\"]\n",
        "\n",
        "if TFP_Installation == \"Nightly\":\n",
        "  !pip install -q tfp-nightly\n",
        "  print(\"Installation of `tfp-nightly` complete.\")\n",
        "elif TFP_Installation == \"0.8.0-rc0\":\n",
        "  !pip install -q --upgrade tensorflow-probability==0.8.0-rc0\n",
        "  print(\"Installation of `tensorflow-probability` complete.\")\n",
        "elif TFP_Installation == \"Stable\":\n",
        "  !pip install -q --upgrade tensorflow-probability\n",
        "  print(\"Installation of `tensorflow-probability` complete.\")\n",
        "elif TFP_Installation == \"System\":\n",
        "  pass\n",
        "else:\n",
        "  raise ValueError(\"Selection Error: Please select a valid \"\n",
        "                   \"installation option.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "YE4E0TjDy22W",
        "colab": {}
      },
      "source": [
        "#@title Check GPU availability and TF version. \n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "print(tf.__version__ )# Has to be 2.0 for this notebook to work..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "-4zKLYqTzFFd",
        "colab": {}
      },
      "source": [
        "#@title Install required python packages and utility packages.\n",
        "#@markdown This installs tf_explain and RAdam, a performant optimizer. Also downloads and imports two helper python sources.\n",
        "# https://github.com/sicara/tf-explain\n",
        "try:\n",
        "  import tf_explain as tfx\n",
        "except:\n",
        "  !pip install tf_explain\n",
        "  import tf_explain as tfx\n",
        "\n",
        "#@markdown Also install talos for easy hyperparameter tuning.\n",
        "try:\n",
        "  import talos\n",
        "except:\n",
        "  !pip install talos\n",
        "  import talos\n",
        "\n",
        "# https://github.com/CyberZHG/keras-radam\n",
        "try:\n",
        "  from keras_radam.training import RAdamOptimizer # for TF\n",
        "except:\n",
        "  !pip install keras-rectified-adam\n",
        "  from keras_radam.training import RAdamOptimizer\n",
        "    \n",
        "from urllib.request import urlopen\n",
        "try:\n",
        "  import utilities\n",
        "except:\n",
        "  url = 'https://github.com/mtwenzel/utilities/raw/master/utilities.py'\n",
        "  resp = urlopen(url)\n",
        "  temp = open(\"utilities.py\", \"wb\")\n",
        "  temp.write(resp.read())\n",
        "  temp.close()\n",
        "  import utilities\n",
        "\n",
        "try:\n",
        "  import data_loaders\n",
        "except:\n",
        "  url = 'https://github.com/mtwenzel/utilities/raw/master/data_loaders.py'\n",
        "  resp = urlopen(url)\n",
        "  temp = open(\"data_loaders.py\", \"wb\")\n",
        "  temp.write(resp.read())\n",
        "  temp.close()\n",
        "  import data_loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4m82bScJy22g",
        "colab": {}
      },
      "source": [
        "#@title Further imports and setup {display-mode:\"form\"}\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input,Conv2D,Dense,GlobalAveragePooling2D,concatenate,Flatten, MaxPooling2D, BatchNormalization, Dropout, SpatialDropout2D\n",
        "from tensorflow.keras.applications import InceptionV3,DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eq4GUBJiy22i",
        "colab": {}
      },
      "source": [
        "#@title Prepare the data. {display-mode:'form'}\n",
        "TARGET_SIZE = (96,96) # Square images because of visualization library...\n",
        "paths_dict = {'train': './data/PPMI-classification/all_2d_train',\n",
        "             'val': './data/PPMI-classification/all_2d_val',\n",
        "             'test': './data/PPMI-classification/all_2d_val'}\n",
        "\n",
        "train_generator, val_generator, test_generator = data_loaders.provide_PPMI_dataset(paths_dict, target_size=TARGET_SIZE)\n",
        "%rm PPMI-classification.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U808MnKQAUbw"
      },
      "source": [
        "# Model Definition and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9sMARety22k",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title This is a performant model definition. It is hard to interpret visualization of this.\n",
        "def get_default_model():\n",
        "  input_image = Input(shape=TARGET_SIZE+(1,))\n",
        "\n",
        "  x = BatchNormalization()(input_image)\n",
        "  x = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', strides=(2,2), name='EarlyConv')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=96, kernel_size=(3,3), activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=96, kernel_size=(3,3), activation='relu', strides=(2,2))(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=96, kernel_size=(3,3), activation='relu', name='MiddleConv')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=96, kernel_size=(3,3), activation='relu', strides=(2,2))(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=128, kernel_size=(3,3), activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', name='LastConv')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  x = Dropout(rate=0.25)(x)\n",
        "\n",
        "  preds = Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "  return Model(inputs=input_image,outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsiM4tMMy22m",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Simple model definition\n",
        "def get_simple_model():\n",
        "  input_image = Input(shape=TARGET_SIZE+(1,))\n",
        "\n",
        "  x = Conv2D(filters=16, kernel_size=(7,7), activation='relu', name='EarlyConv')(input_image)\n",
        "  x = Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
        "  x = Conv2D(filters=64, kernel_size=(5,5), activation='relu')(x)\n",
        "  x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', name='LastConv')(x)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  x = Dropout(rate=0.25)(x)\n",
        "\n",
        "  preds = Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "  return Model(inputs=input_image,outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12uJJHn1y22o",
        "colab": {}
      },
      "source": [
        "model = get_default_model()\n",
        "#model = get_simple_model()\n",
        "model.summary()\n",
        "radam = RAdamOptimizer(learning_rate=1e-3)\n",
        "model.compile(optimizer=radam, loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "7HPYE0wdy22r",
        "colab": {}
      },
      "source": [
        "#@title Create the callbacks for visualization\n",
        "#@markdown To provide some illustration, several callbacks are instantiated. Not all are used below, though.\n",
        "\n",
        "#@markdown Double-click the header row to expand this cell and inspect the definitions. \n",
        "\n",
        "x_val_g = val_generator.next()\n",
        "x_val_img = np.array(x_val_g[0])\n",
        "x_val_lbl = np.array(x_val_g[1])\n",
        "\n",
        "val_class_zero = (np.array([\n",
        "    el for el, label in zip(x_val_img, x_val_lbl)\n",
        "    if np.all(label == np.array([1] + [0]))\n",
        "][0:9]), None)\n",
        "val_class_one = (np.array([\n",
        "    el for el, label in zip(x_val_img, x_val_lbl)\n",
        "    if np.all(label == np.array([0] + [1]))\n",
        "][0:9]), None)\n",
        "\n",
        "#@markdown Which layer to visualize in __GradCam__:\n",
        "LAYER = 'MiddleConv' #@param  ['MiddleConv', 'EarlyConv', 'LastConv']\n",
        "\n",
        "#@markdown __Occlusion Sensitivity__ patch size:\n",
        "PATCH_SIZE = 8 #@param {'type':'integer'}\n",
        "\n",
        "callbacks_CAM = [\n",
        "                 tfx.callbacks.GradCAMCallback(val_class_zero, layer_name='MiddleConv', class_index=0, output_dir='logs/PPMI/GradCam/LastConv/classPD-explPD'),\n",
        "                 tfx.callbacks.GradCAMCallback(val_class_zero, layer_name='MiddleConv', class_index=1, output_dir='logs/PPMI/GradCam/LastConv/classPD-explHC'),\n",
        "                 tfx.callbacks.GradCAMCallback(val_class_one, layer_name='MiddleConv', class_index=0, output_dir='logs/PPMI/GradCam/MiddleConv/classHC-explPD'),\n",
        "                 tfx.callbacks.GradCAMCallback(val_class_one, layer_name='MiddleConv', class_index=1, output_dir='logs/PPMI/GradCam/MiddleConv/classHC-explHC')\n",
        "]\n",
        "callbacks_Occ = [\n",
        "                 tfx.callbacks.OcclusionSensitivityCallback(val_class_zero,class_index=0, patch_size=PATCH_SIZE, output_dir='logs/PPMI/Occlusion/classPD-explPD'),\n",
        "                 tfx.callbacks.OcclusionSensitivityCallback(val_class_zero,class_index=1, patch_size=PATCH_SIZE, output_dir='logs/PPMI/Occlusion/classPD-explHC'),\n",
        "                 tfx.callbacks.OcclusionSensitivityCallback(val_class_one,class_index=0, patch_size=PATCH_SIZE, output_dir='logs/PPMI/Occlusion/classHC-explPD'),\n",
        "                 tfx.callbacks.OcclusionSensitivityCallback(val_class_one,class_index=1, patch_size=PATCH_SIZE, output_dir='logs/PPMI/Occlusion/classHC-explHC')\n",
        "]\n",
        "\n",
        "tf_cb = tf.keras.callbacks.TensorBoard(histogram_freq=5, log_dir='logs/PPMI/metrics')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aj-_CxmLy22t",
        "colab": {}
      },
      "source": [
        "# train the model on the new data for a few epochs. Use the callbacks only afterwards to speed up the process.\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                              epochs=50,\n",
        "                             validation_data=val_generator,\n",
        "                             validation_steps=val_generator.n//val_generator.batch_size,\n",
        "                             verbose=0,\n",
        "                             callbacks=[tf_cb])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFZ2ADwly22v",
        "colab": {}
      },
      "source": [
        "# After that, only train two epochs to generate the visualizations. This is costly!\n",
        "# Look into the embedded TensorBoard above to see results.\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                              epochs=10,\n",
        "                             validation_data=val_generator,\n",
        "                             validation_steps=val_generator.n//val_generator.batch_size,\n",
        "                             verbose=2,\n",
        "                             callbacks=callbacks_CAM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdIeQtbtEqeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zs9m2uLty22d",
        "colab": {}
      },
      "source": [
        "import datetime, os\n",
        "\n",
        "logs_base_dir = \"./logs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM25PsLXrMQH",
        "colab_type": "text"
      },
      "source": [
        "## Use `tf_explain` core to explain predictions directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sweHhN0qrUpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tf_explain.core.smoothgrad import SmoothGrad\n",
        "from tf_explain.core.grad_cam import GradCAM\n",
        "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "explainer = SmoothGrad()\n",
        "gridSmoothGrad = explainer.explain(val_class_zero, model, class_index=0, num_samples=20, noise=1.)\n",
        "\n",
        "explainer = GradCAM()\n",
        "gridGradCam = explainer.explain(validation_data=val_class_zero, model=model, layer_name='MiddleConv', class_index=0)\n",
        "\n",
        "explainer = OcclusionSensitivity()\n",
        "gridOccl = explainer.explain(val_class_zero, model, class_index=0, patch_size=4)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(gridSmoothGrad)\n",
        "plt.show()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(gridGradCam)\n",
        "plt.show()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(gridOccl)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "15B2xvXPAyCd"
      },
      "source": [
        "# A toy example from the `tf_explain` authors.\n",
        "\n",
        "The original code by the tf_explain authors, taken from https://github.com/sicara/tf-explain/blob/master/examples/callbacks/mnist.py\n",
        "\n",
        "The original code does not cast the input data to float. This may cause a crash depending on TF version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uUaQEVhNy22_",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tf_explain\n",
        "\n",
        "INPUT_SHAPE = (28, 28, 1)\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "AVAILABLE_DATASETS = {\n",
        "    'mnist': tf.keras.datasets.mnist,\n",
        "    'fashion_mnist': tf.keras.datasets.fashion_mnist,\n",
        "}\n",
        "DATASET_NAME = 'fashion_mnist'  # Choose between \"mnist\" and \"fashion_mnist\"\n",
        "\n",
        "# Load dataset\n",
        "dataset = AVAILABLE_DATASETS[DATASET_NAME]\n",
        "(train_images, train_labels), (test_images, test_labels) = dataset.load_data()\n",
        "train_images = train_images.astype(np.float32)\n",
        "test_images = test_images.astype(np.float32)\n",
        "\n",
        "# Convert from (28, 28) images to (28, 28, 1)\n",
        "train_images = train_images[..., tf.newaxis]\n",
        "test_images = test_images[..., tf.newaxis]\n",
        "\n",
        "# One hot encore labels 0, 1, .., 9 to [0, 0, .., 1, 0, 0]\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Small function to get some instances of one class for testing (0-indexed)\n",
        "def get_validation_instances(class_idx, num_instances):\n",
        "  return (np.array([\n",
        "      el for el, label in zip(test_images, test_labels)\n",
        "      if np.all(label == np.array(class_idx * [0] + [1] + (NUM_CLASSES - class_idx - 1) * [0]))\n",
        "  ][0:num_instances]), None)\n",
        "\n",
        "def demo_model(x_train, y_train, x_val, y_val, params):\n",
        "  # Create model\n",
        "  img_input = tf.keras.Input(INPUT_SHAPE)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(img_input)\n",
        "  x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name='target_layer')(x)\n",
        "  x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.25)(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "  model = tf.keras.Model(img_input, x)\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Get some validation images    \n",
        "  validation_class_zero = get_validation_instances(class_idx=0, num_instances=9)\n",
        "  validation_class_eight = get_validation_instances(class_idx=7, num_instances=9)\n",
        "  validation_class_three = get_validation_instances(class_idx=3, num_instances=9)\n",
        "  validation_class_nine = get_validation_instances(class_idx=9, num_instances=9)\n",
        "\n",
        "  # Instantiate callbacks\n",
        "  # class_index value should match the validation_data selected above\n",
        "  callbacks_mnist_GradCAM = [\n",
        "      tf_explain.callbacks.GradCAMCallback(validation_class_three, 'target_layer', class_index=3, output_dir='logs/GradCam/class3-expl3'),\n",
        "      tf_explain.callbacks.GradCAMCallback(validation_class_three, 'target_layer', class_index=9, output_dir='logs/GradCam/class3-expl9'),\n",
        "      tf_explain.callbacks.GradCAMCallback(validation_class_nine, 'target_layer', class_index=3, output_dir='logs/GradCam/class9-expl3'),\n",
        "      tf_explain.callbacks.GradCAMCallback(validation_class_nine, 'target_layer', class_index=9, output_dir='logs/GradCam/class9-expl9'),\n",
        "  ]\n",
        "  \n",
        "  callbacks_mnist_Occl = [\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_three, class_index=3, patch_size=params['patch_size'], output_dir='logs/MNIST/Occl/class3-expl3/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_three, class_index=9, patch_size=params['patch_size'], output_dir='logs/MNIST/Occl/class3-expl9/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_nine, class_index=3, patch_size=params['patch_size'], output_dir='logs/MNIST/Occl/class9-expl3/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_nine, class_index=9, patch_size=params['patch_size'], output_dir='logs/MNIST/Occl/class9-expl9/patch'+str(params['patch_size'])),\n",
        "  ]\n",
        "  \n",
        "  callbacks_fashion_mnist_Occl = [\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_eight, class_index=7, patch_size=params['patch_size'], output_dir='logs/F-MNIST/Occl/class7-expl7/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_eight, class_index=9, patch_size=params['patch_size'], output_dir='logs/F-MNIST/Occl/class7-expl9/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_nine, class_index=3, patch_size=params['patch_size'], output_dir='logs/F-MNIST/Occl/class9-expl7/patch'+str(params['patch_size'])),\n",
        "      tf_explain.callbacks.OcclusionSensitivityCallback(validation_class_nine, class_index=9, patch_size=params['patch_size'], output_dir='logs/F-MNIST/Occl/class9-expl9/patch'+str(params['patch_size'])),\n",
        "  ]\n",
        "  # Start training\n",
        "  out = model.fit(x_train, y_train, epochs=15, callbacks=callbacks_fashion_mnist)\n",
        "  return out, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ut8tyXxUPlZ",
        "colab_type": "text"
      },
      "source": [
        "## Use Talos for hyperparameter tuning\n",
        "\n",
        "We can 'misuse' the talos package which is originally intended to ease hyperparameter tuning to run a batch of experiments, in this case changing the size of the occlusion patch between 4 and 12 in increments of 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5YXD_jCQh2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = {\n",
        "    'patch_size': [4, 6, 8, 10]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IvBwH_aHy23D",
        "colab": {}
      },
      "source": [
        "h = talos.Scan(train_images.astype(np.float32), train_labels, p, demo_model, 'patchsize')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tErWkIMb25Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/logs.zip /content/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbz0Dw7I7Ysd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/logs.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LpcSKgn7jnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
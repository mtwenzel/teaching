{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Probability - Prob Layers PPMI Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtwenzel/teaching/blob/master/05 Probability PPMI Classification Prob Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX8UEkhDjv04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Legal Notice {display-mode:'form'}\n",
        "#@markdown Copyright 2019 (Modifications/adaptions) by Fraunhofer MEVIS, Bremen/Hamburg\n",
        "\n",
        "#@markdown Original Code: Copyright 2018 The TensorFlow Probability Authors.\n",
        "\n",
        "#@markdown The original code is licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "\n",
        "#@markdown You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "#@markdown Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "#@markdown Parts of the code have been adapted from https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHDGVS7Tjv0-",
        "colab_type": "code",
        "outputId": "55ccc90d-31fc-422a-ecad-4a9529640cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#@title Imports and data download. {display-mode:'form'}\n",
        "# Trains a Bayesian neural network to classify DAT scan images.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import pathlib\n",
        "import random\n",
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Dependency imports\n",
        "from absl import flags\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "%matplotlib notebook\n",
        "from matplotlib import figure  # pylint: disable=g-import-not-at-top\n",
        "from matplotlib.backends import backend_agg\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.layers import Input,Dense,GlobalAveragePooling2D,Flatten,concatenate,BatchNormalization, Dropout\n",
        "from tensorflow.keras.applications import InceptionV3,DenseNet121\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# For TF2, eager execution will break some code, so disable for now.\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "warnings.simplefilter(action=\"ignore\")\n",
        "\n",
        "try:\n",
        "  import seaborn as sns  # pylint: disable=g-import-not-at-top\n",
        "  HAS_SEABORN = True\n",
        "except ImportError:\n",
        "  HAS_SEABORN = False\n",
        "\n",
        "tfd = tfp.distributions\n",
        "\n",
        "zipurl = 'https://github.com/mtwenzel/parkinson-classification/raw/master/data/PPMI-classification.zip'\n",
        "zipresp = urlopen(zipurl)\n",
        "tempzip = open(\"PPMI-classification.zip\", \"wb\")\n",
        "tempzip.write(zipresp.read())\n",
        "tempzip.close()\n",
        "print(\"download complete, extracting...\")\n",
        "\n",
        "zf = ZipFile(\"PPMI-classification.zip\")\n",
        "zf.extractall(path = 'data/')\n",
        "zf.close()\n",
        "print(\"... done\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download complete, extracting...\n",
            "... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8wMSVyrjv1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Parameters {display-mode:'form', run:'auto'}\n",
        "\n",
        "# PPMI\n",
        "IMAGE_SHAPE = [109, 91]\n",
        "num_classes = 2\n",
        "\n",
        "learning_rate = 0.001\n",
        "max_steps = 2000 #@param {type:'integer'}\n",
        "batch_size = 128 #@param {type:'integer'}\n",
        "data_dir  = os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"ppmi_basemodel_bnn/data\")\n",
        "model_dir = os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"ppmi_basemodel_bnn_original/\")\n",
        "viz_steps = 250 #@param {type:'integer'}\n",
        "num_monte_carlo = 50 #@param {type:'integer'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXJISvrejv1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Function definitions {display-mode:'form'}\n",
        "#@markdown Plotting of validation images and weight distributions.\n",
        "def plot_weight_posteriors(names, qm_vals, qs_vals, fname):\n",
        "  \"\"\"Save a PNG plot with histograms of weight means and stddevs.\n",
        "\n",
        "  Args:\n",
        "    names: A Python `iterable` of `str` variable names.\n",
        "    qm_vals: A Python `iterable`, the same length as `names`,\n",
        "      whose elements are Numpy `array`s, of any shape, containing\n",
        "      posterior means of weight varibles.\n",
        "    qs_vals: A Python `iterable`, the same length as `names`,\n",
        "      whose elements are Numpy `array`s, of any shape, containing\n",
        "      posterior standard deviations of weight varibles.\n",
        "    fname: Python `str` filename to save the plot to.\n",
        "  \"\"\"\n",
        "  fig = figure.Figure(figsize=(6, 3))\n",
        "  canvas = backend_agg.FigureCanvasAgg(fig)\n",
        "\n",
        "  ax = fig.add_subplot(1, 2, 1)\n",
        "  for n, qm in zip(names, qm_vals):\n",
        "    sns.distplot(qm.flatten(), ax=ax, label=n)\n",
        "  ax.set_title(\"weight means\")\n",
        "  ax.set_xlim([-1.5, 1.5])\n",
        "  ax.legend()\n",
        "\n",
        "  ax = fig.add_subplot(1, 2, 2)\n",
        "  for n, qs in zip(names, qs_vals):\n",
        "    sns.distplot(qs.flatten(), ax=ax)\n",
        "  ax.set_title(\"weight stddevs\")\n",
        "  ax.set_xlim([0, 1.])\n",
        "\n",
        "  fig.tight_layout()\n",
        "  canvas.print_figure(fname, format=\"png\")\n",
        "  print(\"saved {}\".format(fname))\n",
        "\n",
        "\n",
        "def plot_heldout_prediction(input_vals, probs,\n",
        "                            fname, n=10, offset=0, title=\"\"):\n",
        "  \"\"\"Save a PNG plot visualizing posterior uncertainty on heldout data.\n",
        "\n",
        "  Args:\n",
        "    input_vals: A `float`-like Numpy `array` of shape\n",
        "      `[num_heldout] + IMAGE_SHAPE`, containing heldout input images.\n",
        "    probs: A `float`-like Numpy array of shape `[num_monte_carlo,\n",
        "      num_heldout, num_classes]` containing Monte Carlo samples of\n",
        "      class probabilities for each heldout sample.\n",
        "    fname: Python `str` filename to save the plot to.\n",
        "    n: Python `int` number of datapoints to vizualize.\n",
        "    offset: Python 'int' offset into the data if not wishing to visualize first 'n' examples\n",
        "    title: Python `str` title for the plot.\n",
        "  \"\"\"\n",
        "  fig = figure.Figure(figsize=(9, 3*n))\n",
        "  canvas = backend_agg.FigureCanvasAgg(fig)\n",
        "  for i in range(offset, offset+n):\n",
        "    ax = fig.add_subplot(n, 3, 3*(i-offset) + 1)\n",
        "    ax.imshow(input_vals[i, :].reshape(IMAGE_SHAPE), interpolation=\"None\")\n",
        "\n",
        "    ax = fig.add_subplot(n, 3, 3*(i-offset) + 2)\n",
        "    for prob_sample in probs:\n",
        "      sns.barplot(np.arange(num_classes), prob_sample[i, :], alpha=0.1, ax=ax)\n",
        "      ax.set_ylim([0, 1])\n",
        "    ax.set_title(\"posterior samples\")\n",
        "\n",
        "    ax = fig.add_subplot(n, 3, 3*(i-offset) + 3)\n",
        "    sns.barplot(np.arange(num_classes), np.mean(probs[:, i, :], axis=0), ax=ax)\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.set_title(\"predictive probs\")\n",
        "  fig.suptitle(title)\n",
        "  fig.tight_layout()\n",
        "\n",
        "  canvas.print_figure(fname, format=\"png\")\n",
        "  print(\"saved {}\".format(fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUaI0lsMleZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4a31447-7933-4e63-f8cb-cfec714a53df"
      },
      "source": [
        "#@title Check GPU availability {display-mode: 'form'}\n",
        "#@markdown If you don't see a GPU in Colab, activate it by selecting *Runtime -> Change Runtime Type* in the menu. You can inspect details with code commented out below.\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "#print('')\n",
        "#print('Detailed information:')\n",
        "#print('---------------------')\n",
        "#from tensorflow.python.client import device_lib\n",
        "#print(device_lib.list_local_devices())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpUSDe-8ljC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Set the data generators. {display-mode:'form', run: \"auto\"}\n",
        "#@markdown Currently not used!\n",
        "\n",
        "#@markdown Data augmentation choices. Cell runs automatically if anything is changed.\n",
        "shear_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "zoom_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "width_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "height_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "rotation_range = 10 #@param {type:\"slider\", min:0, max:90, step:5}\n",
        "horizontal_flip = True #@param {type:\"boolean\"}\n",
        "vertical_flip = False #@param {type:\"boolean\"}\n",
        "#@markdown Data source (No need to change if the download succeeded.)\n",
        "data_directory = '/content/data/PPMI-classification/' #@param ['z:/Data/Parkinson_DATScans UKE/full_ppmi_data/png/', '/content/drive/My Drive/MEVIS/Data/PPMI-classification/'] {allow-input: true}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCC7JHC0-GCr",
        "colab_type": "text"
      },
      "source": [
        "## Create a tf.data.Dataset from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j7Kgj2i_LX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Function definitions and parameters {display-mode:\"form\"}\n",
        "#@markdown Set the data paths here, if they are different in your setting.\n",
        "# This uses code from the TensorFlow tutorials at https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_path = '/content/data/PPMI-classification/all_2d_train/' #@param {type:\"string\"}\n",
        "valid_path = '/content/data/PPMI-classification/all_2d_val/'  #@param {type:\"string\"}\n",
        "model_dir = '/content/tmp/test/' #@param {type:\"string\"}\n",
        "download_dir = '/content/tmp/test/' #@param {type:\"string\"}\n",
        "train_data_root = pathlib.Path(train_path) \n",
        "valid_data_root = pathlib.Path(valid_path) \n",
        "\n",
        "def preprocess_image(image):\n",
        "  image = tf.image.decode_png(image,channels=1)\n",
        "  image = tf.image.resize(image, IMAGE_SHAPE)\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "\n",
        "  return image\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  image = tf.read_file(path)\n",
        "  return preprocess_image(image)\n",
        "\n",
        "def get_dataset(data_root):\n",
        "  all_image_paths = list(data_root.glob('*/*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  image_count = len(all_image_paths)\n",
        "  print(data_root, image_count)\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                      for path in all_image_paths]\n",
        "\n",
        "  path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "  image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
        "  image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "  return image_label_ds, image_count\n",
        "\n",
        "def build_input_pipeline(training_dataset, heldout_dataset, batch_size, train_size, heldout_size):\n",
        "    \"\"\"Build an Iterator switching between train and heldout data.\"\"\"\n",
        "\n",
        "    # Build an iterator over training batches.\n",
        "    training_batches = training_dataset.shuffle(train_size, reshuffle_each_iteration=True).repeat().batch(batch_size)\n",
        "    training_iterator = tf.compat.v1.data.make_one_shot_iterator(training_batches)\n",
        "\n",
        "    # Build a iterator over the heldout set with batch_size=heldout_size,\n",
        "    # i.e., return the entire heldout set as a constant.\n",
        "    heldout_frozen = (heldout_dataset.take(heldout_size).repeat().batch(heldout_size))\n",
        "    heldout_iterator = tf.compat.v1.data.make_one_shot_iterator(heldout_frozen)\n",
        "\n",
        "    # Combine these into a feedable iterator that can switch between training\n",
        "    # and validation inputs.\n",
        "    handle = tf.compat.v1.placeholder(tf.string, shape=[])\n",
        "    feedable_iterator = tf.compat.v1.data.Iterator.from_string_handle(\n",
        "        handle, \n",
        "        tf.compat.v1.data.get_output_types(training_batches), \n",
        "        tf.compat.v1.data.get_output_shapes(training_batches))\n",
        "    images, labels = feedable_iterator.get_next()\n",
        "\n",
        "    return images, labels, handle, training_iterator, heldout_iterator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIWi4OK7jv1M",
        "colab_type": "code",
        "outputId": "fd445d80-eb95-4e72-d0b1-28fbccc680b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if tf.io.gfile.exists(model_dir):\n",
        "    tf.compat.v1.logging.warning(\"Warning: deleting old log directory at {}\".format(model_dir))\n",
        "    tf.io.gfile.rmtree(model_dir)\n",
        "tf.io.gfile.makedirs(model_dir)\n",
        "\n",
        "train_data, num_train_data = get_dataset(train_data_root)\n",
        "valid_data, num_valid_data = get_dataset(valid_data_root)\n",
        "\n",
        "(images, labels, handle, training_iterator, heldout_iterator) = build_input_pipeline(train_data, valid_data, batch_size, num_train_data, num_valid_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/PPMI-classification/all_2d_train 1097\n",
            "/content/data/PPMI-classification/all_2d_val 193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl6PY_tPfmWs",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r1NXHlBvkEI",
        "colab_type": "text"
      },
      "source": [
        "We use Flipout for linear variance reduction in the weights as proposed in https://arxiv.org/abs/1803.04386. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoG3f-8vjv1S",
        "colab_type": "code",
        "outputId": "644def98-b928-4df9-c22f-76c762b28377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "# Custom network with all probabilistic layers\n",
        "with tf.compat.v1.name_scope(\"bayesian_neural_net\", values=[images]):\n",
        "    neural_net = tf.keras.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tfp.layers.Convolution2DFlipout(64, kernel_size=3, activation=tf.nn.relu),\n",
        "#        tf.keras.layers.BatchNormalization(),\n",
        "#        tfp.layers.Convolution2DFlipout(64, kernel_size=3, activation=tf.nn.relu),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2]),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tfp.layers.Convolution2DFlipout(64, kernel_size=3, activation=tf.nn.relu),\n",
        "#        tf.keras.layers.BatchNormalization(),\n",
        "#        tfp.layers.Convolution2DFlipout(64, kernel_size=3, activation=tf.nn.relu),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2]),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tfp.layers.Convolution2DFlipout(96, kernel_size=3, activation=tf.nn.relu),\n",
        "#        tf.keras.layers.BatchNormalization(),\n",
        "#        tfp.layers.Convolution2DFlipout(96, kernel_size=3, activation=tf.nn.relu),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2]),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tfp.layers.Convolution2DFlipout(128, kernel_size=3, activation=tf.nn.relu),\n",
        "#        tf.keras.layers.BatchNormalization(),\n",
        "#        tfp.layers.Convolution2DFlipout(128, kernel_size=3, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tfp.layers.DenseFlipout(128, activation=tf.nn.relu),\n",
        "        tfp.layers.DenseFlipout(num_classes)\n",
        "    ])\n",
        "\n",
        "    logits = neural_net(images)\n",
        "    labels_distribution = tfd.Categorical(logits=logits)\n",
        "\n",
        "neural_net.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo multiple                  4         \n",
            "_________________________________________________________________\n",
            "conv2d_flipout (Conv2DFlipou multiple                  1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch multiple                  256       \n",
            "_________________________________________________________________\n",
            "conv2d_flipout_1 (Conv2DFlip multiple                  73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  256       \n",
            "_________________________________________________________________\n",
            "conv2d_flipout_2 (Conv2DFlip multiple                  110688    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch multiple                  384       \n",
            "_________________________________________________________________\n",
            "conv2d_flipout_3 (Conv2DFlip multiple                  221312    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch multiple                  32256     \n",
            "_________________________________________________________________\n",
            "dense_flipout (DenseFlipout) multiple                  2064512   \n",
            "_________________________________________________________________\n",
            "dense_flipout_1 (DenseFlipou multiple                  514       \n",
            "=================================================================\n",
            "Total params: 2,505,190\n",
            "Trainable params: 2,488,612\n",
            "Non-trainable params: 16,578\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sBuAsSjjv1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the -ELBO as the loss, averaged over the batch size.\n",
        "neg_log_likelihood = -tf.reduce_mean(input_tensor=labels_distribution.log_prob(labels))\n",
        "kl = sum(neural_net.losses) / num_train_data\n",
        "elbo_loss = neg_log_likelihood + kl\n",
        "\n",
        "# Build metrics for evaluation. Predictions are formed from a single forward\n",
        "# pass of the probabilistic layers. They are cheap but noisy predictions.\n",
        "predictions = tf.argmax(input=logits, axis=1)\n",
        "accuracy, accuracy_update_op = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predictions)\n",
        "\n",
        "# Extract weight posterior statistics for layers with weight distributions\n",
        "# for later visualization.\n",
        "names = []\n",
        "qmeans = []\n",
        "qstds = []\n",
        "for i, layer in enumerate(neural_net.layers):\n",
        "    try:\n",
        "        q = layer.kernel_posterior\n",
        "    except AttributeError:\n",
        "        continue\n",
        "    names.append(\"Layer {}\".format(i))\n",
        "    qmeans.append(q.mean())\n",
        "    qstds.append(q.stddev())\n",
        "\n",
        "with tf.compat.v1.name_scope(\"train\"):\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(elbo_loss)\n",
        "\n",
        "init_op = tf.group(tf.compat.v1.global_variables_initializer(), tf.compat.v1.local_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pW5Mz-sfrVv",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobQMKs0ENLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From https://arxiv.org/pdf/1812.03973.pdf:\n",
        "# Alternatively, run the following instead of a manual train_op.\n",
        "neural_net.compile(optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate), loss=’categorical_crossentropy’, metrics=[’accuracy’])\n",
        "neural_net.fit(features, labels, batch_size=32, epochs=5)\n",
        "\n",
        "# When converting classification TFP code from TF1.x to TF2.x, \n",
        "# replacing the KLD in the ELBO may be done with the tfp.layers.KLDivergenceAddLoss layer, just using standard cross-entropy loss.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJv7jP_Wjv1Y",
        "colab_type": "code",
        "outputId": "7e8c59f8-9bf5-462b-93fb-17c530972069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "best_loss = np.inf\n",
        "best_loss_iter = 0\n",
        "best_weights = neural_net.get_weights()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "    # Run the training loop.\n",
        "    train_handle = sess.run(training_iterator.string_handle())\n",
        "    heldout_handle = sess.run(heldout_iterator.string_handle())\n",
        "    for step in range(max_steps):\n",
        "        _ = sess.run([train_op, accuracy_update_op], feed_dict={handle: train_handle})\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            loss_value, accuracy_value = sess.run([elbo_loss, accuracy], feed_dict={handle: train_handle})\n",
        "\n",
        "            # save best model\n",
        "            if loss_value < best_loss:\n",
        "                print(\"Saving new best model at Step: {:>5d} Loss: {:.4f} Accuracy: {:.4f}\".format(step, loss_value, accuracy_value))\n",
        "                best_loss = loss_value\n",
        "                best_loss_iter = step\n",
        "                best_weights = neural_net.get_weights()\n",
        "            else:\n",
        "                print(\"Step: {:>5d} Loss: {:.4f} Accuracy: {:.4f}\".format(step, loss_value, accuracy_value))\n",
        "\n",
        "\n",
        "        if (step+1) % viz_steps == 0:\n",
        "            # Compute log prob of heldout set by averaging draws from the model:\n",
        "            # p(heldout | train) = int_model p(heldout|model) p(model|train)\n",
        "            #                   ~= 1/n * sum_{i=1}^n p(heldout | model_i)\n",
        "            # where model_i is a draw from the posterior p(model|train).\n",
        "            probs = np.asarray([sess.run((labels_distribution.probs),\n",
        "                                     feed_dict={handle: heldout_handle})\n",
        "                            for _ in range(num_monte_carlo)])\n",
        "            mean_probs = np.mean(probs, axis=0)\n",
        "\n",
        "            image_vals, label_vals = sess.run((images, labels), feed_dict={handle: heldout_handle})\n",
        "            heldout_lp = np.mean(np.log(mean_probs[np.arange(mean_probs.shape[0]), label_vals.flatten()]))\n",
        "            print(\" ... Held-out nats: {:.4f}\".format(heldout_lp))\n",
        "\n",
        "            qm_vals, qs_vals = sess.run((qmeans, qstds))\n",
        "\n",
        "            if HAS_SEABORN:\n",
        "                plot_weight_posteriors(names, qm_vals, qs_vals,\n",
        "                                 fname=os.path.join(\n",
        "                                     model_dir,\n",
        "                                     \"step{:05d}_weights.png\".format(step)))\n",
        "\n",
        "                plot_heldout_prediction(image_vals, probs, n=20, offset=55,\n",
        "                                  fname=os.path.join(\n",
        "                                      model_dir,\n",
        "                                      \"step{:05d}_pred.png\".format(step)),\n",
        "                                  title=\"mean heldout logprob {:.2f}\"\n",
        "                                  .format(heldout_lp))\n",
        "                \n",
        "    # Evaluate best model\n",
        "    print(\"Evaluating best model from iter {:>5d}:\".format(best_loss_iter))\n",
        "    neural_net.set_weights(best_weights)\n",
        "\n",
        "    heldout_handle = sess.run(heldout_iterator.string_handle())\n",
        "    image_vals, label_vals = sess.run((images, labels), feed_dict={handle: heldout_handle})\n",
        "    heldout_lp = np.mean(np.log(mean_probs[np.arange(mean_probs.shape[0]), label_vals.flatten()]))\n",
        "\n",
        "    print(\" ... Held-out nats: {:.4f}\".format(heldout_lp)) \n",
        "    \n",
        "    qm_vals, qs_vals = sess.run((qmeans, qstds))\n",
        "\n",
        "    if HAS_SEABORN:\n",
        "        plot_weight_posteriors(names, qm_vals, qs_vals,\n",
        "                         fname=os.path.join(\n",
        "                             model_dir,\n",
        "                             \"best_step{:05d}_weights.png\".format(best_loss_iter)))\n",
        "\n",
        "        plot_heldout_prediction(image_vals, probs, n=20, offset=55,\n",
        "                          fname=os.path.join(\n",
        "                              model_dir,\n",
        "                              \"best_step{:05d}_pred.png\".format(best_loss_iter)),\n",
        "                          title=\"mean heldout logprob {:.2f}\"\n",
        "                          .format(heldout_lp))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving new best model at Step:     0 Loss: 2864.0652 Accuracy: 0.6641\n",
            "Saving new best model at Step:   100 Loss: 2740.0776 Accuracy: 0.7191\n",
            "Saving new best model at Step:   200 Loss: 2630.2827 Accuracy: 0.8211\n",
            " ... Held-out nats: -0.0953\n",
            "saved /content/tmp/test/step00249_weights.png\n",
            "saved /content/tmp/test/step00249_pred.png\n",
            "Saving new best model at Step:   300 Loss: 2521.4866 Accuracy: 0.8654\n",
            "Saving new best model at Step:   400 Loss: 2413.3696 Accuracy: 0.8892\n",
            " ... Held-out nats: -0.0656\n",
            "saved /content/tmp/test/step00499_weights.png\n",
            "saved /content/tmp/test/step00499_pred.png\n",
            "Saving new best model at Step:   500 Loss: 2306.1060 Accuracy: 0.9050\n",
            "Saving new best model at Step:   600 Loss: 2199.8037 Accuracy: 0.9153\n",
            "Saving new best model at Step:   700 Loss: 2094.2632 Accuracy: 0.9226\n",
            " ... Held-out nats: -0.0725\n",
            "saved /content/tmp/test/step00749_weights.png\n",
            "saved /content/tmp/test/step00749_pred.png\n",
            "Saving new best model at Step:   800 Loss: 1989.8492 Accuracy: 0.9281\n",
            "Saving new best model at Step:   900 Loss: 1886.5215 Accuracy: 0.9322\n",
            " ... Held-out nats: -0.0690\n",
            "saved /content/tmp/test/step00999_weights.png\n",
            "saved /content/tmp/test/step00999_pred.png\n",
            "Saving new best model at Step:  1000 Loss: 1784.4094 Accuracy: 0.9355\n",
            "Saving new best model at Step:  1100 Loss: 1683.7844 Accuracy: 0.9383\n",
            "Saving new best model at Step:  1200 Loss: 1584.4303 Accuracy: 0.9402\n",
            " ... Held-out nats: -0.0750\n",
            "saved /content/tmp/test/step01249_weights.png\n",
            "saved /content/tmp/test/step01249_pred.png\n",
            "Saving new best model at Step:  1300 Loss: 1486.8892 Accuracy: 0.9417\n",
            "Saving new best model at Step:  1400 Loss: 1391.1399 Accuracy: 0.9429\n",
            " ... Held-out nats: -0.0790\n",
            "saved /content/tmp/test/step01499_weights.png\n",
            "saved /content/tmp/test/step01499_pred.png\n",
            "Saving new best model at Step:  1500 Loss: 1297.4731 Accuracy: 0.9439\n",
            "Saving new best model at Step:  1600 Loss: 1205.8252 Accuracy: 0.9443\n",
            "Saving new best model at Step:  1700 Loss: 1116.6632 Accuracy: 0.9448\n",
            " ... Held-out nats: -0.0913\n",
            "saved /content/tmp/test/step01749_weights.png\n",
            "saved /content/tmp/test/step01749_pred.png\n",
            "Saving new best model at Step:  1800 Loss: 1030.1974 Accuracy: 0.9449\n",
            "Saving new best model at Step:  1900 Loss: 946.5250 Accuracy: 0.9451\n",
            " ... Held-out nats: -0.0938\n",
            "saved /content/tmp/test/step01999_weights.png\n",
            "saved /content/tmp/test/step01999_pred.png\n",
            "Evaluating best model from iter  1900:\n",
            " ... Held-out nats: -0.0938\n",
            "saved /content/tmp/test/best_step01900_weights.png\n",
            "saved /content/tmp/test/best_step01900_pred.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfKaU8rTrdUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "440f6924-48ba-4180-e1f6-4be47b6b9392"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/user_drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/user_drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEE5Mng4jv1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the model temporarily into the Colab Files area\n",
        "neural_net.save('/content/user_drive/My Drive/MEVIS/Projects/DeepLearning/ParkinsonClassificationSPECT/tmp/test/best_weights.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQe7dd3QrtYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
